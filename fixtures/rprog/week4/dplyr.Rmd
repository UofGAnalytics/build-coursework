## Efficient data manipulation using dplyr

####[video, videoid="uOo4s_s15aI", duration="14m26s"] Efficient data manipulation using dplyr


In this section we will work with data from Paris' Vélib' bicycle sharing system available through [JCDecaux's API](https://developer.jcdecaux.com/) for [open cycle data](https://developer.jcdecaux.com/#/opendata/).

The data consists of the number of bikes available and the number of  bike stands available at every Vélib' station, recorded every five minutes over six hours on a Tuesday afternoon in October 2017.

The data consists of two tibbles. The first, `bikes` contains data on the number of available bikes and stands at each station.

|Variable    |Description         |
|------------|--------------------|
|`name`      |Name of the station |
|`available_bikes`|Number of available at that time|
|`available_bike_stands`|Number of available bike stands|
|`time`  |Decimal time for which the number have been recorded|

The second, `stations` contains additional information about each station.

|Variable    |Description         |
|------------|--------------------|
|`name`      |Unique name of the station |
|`id`        |Internal ID number of the station |
|`address`   |Address of where the station is located|
|`lng`       |GPS coordinate (longitude) |
|`lat`       |GPS coordinate (latitude)  |
|`departement`|Département in which the station is located|

You can load the data into R using
```{r}
library(tibble)
load(url("http://www.stats.gla.ac.uk/~levers/rp/velib.RData"))
```

### Overview: the key functions ("verbs") for `dplyr`

| Function ("verb") | Description | R base equivalent(s) | SQL equivalent |
|---------|-----------------------|----------------|----------------|
|`filter` |Select observations/rows|`subset`| `WHERE ...` (also `HAVING ...`)|
|`slice`|Select observations by row numbers|`[idx,]`|(vendor dependent)|
|`select` |Select variables/column |`$` or `[,sel]`| | `SELECT ...`|
|`mutate` |Create new variables/column|`transform` | `SELECT ... AS ...` |
|`arrange`|Sort observations/rows | `order`  |`ORDER BY ... `|
|`group_by`|Group observations by variable |`by` or `aggregate`| `GROUP BY ...`|
|`summarise`|Calculate summary statistics |`by` or `aggregate`|`SELECT ...` with `GROUP BY`|

The functions in `dplyr` are designed to be used with tibbles, but they also work with data frames. When invoked with a data frame, they will return a data frame as long as this is possible.

### Selecting observations (rows) using `filter` and `slice`
#### `filter`
The function `filter` is used to select observations (or rows) in a similar way to the base R function `subset`.

Suppose we want to print all bike stations in Paris (rather than other départements from Île de France)
```{r}
library(dplyr)
stations75 <- stations %>%
                filter(departement=="Paris")
stations75
```
Note the use of a double `==` to test whether the département is equal to "Paris".

We can create more complex expressions using the standard logical operators `&` ("and"), `|` ("or") and `!` ("not"). Note that you *cannot* use `&&` and `||` in this context, as they only work with scalar arguments.

For example, if we want to extract the stations which are in Paris or Hauts-de-Seine we can use
```{r}
stations7592 <- stations %>%
                  filter(departement=="Paris" | departement=="Hauts-de-Seine")
```
Rather than using a logical or we could have used `%in%`:
```{r}
stations7592 <- stations %>%
                  filter(departement %in% c("Paris" , "Hauts-de-Seine"))
```

Even though the functions from `dplyr` are designed to be used with pipelines, you can also provide the data set as first argument:
```{r, eval=FALSE}
stations7592 <- filter(stations, departement %in% c("Paris" , "Hauts-de-Seine"))
```

#### `slice`
You can use the function `slice` to select observations based on their row numbers.
```{r}
stations %>%
  slice(5:7)
```
selects the observations in rows 5 to 7 and is equivalent to
```{r}
stations[5:7,]
```

####[task]
Identify the stations which had more than 60 bikes available at 3pm (i.e. `time` taking the value 15). 
#####[answer]
You can use the following R code:
```{r}
bikes %>%
  filter(time==15 & available_bikes>60)
```
#####[/answer]
####[/task]

### Selecting variables (columns) using `select`
The function `select` can be used to subset the variables (columns) of a data set.

You can either specify the columns to retain or (with a minus) those you do not want to retain.

We can only retain the name and département of each station using either
```{r}
stations.small <- stations %>%
                     select(name, departement)
stations.small
```
or
```{r}
stations.small <- stations %>% select(-id, -address, -lng, -lat)
```
You can also use `select` to change the order of the columns of a data set.

### Adding new variables using `mutate`
The function `mutate` can be used to create new variables (columns) in a data set. `mutate` is similar in functionality to the base R function `transform`.

We can add the total number of stands to the data set `bikes` using
```{r}
bikes <- bikes %>%
           mutate(total_stands = available_bikes+available_bike_stands)
```

More than one new variable can be defined by adding further arguments to `mutate`.

`transmute` is a sibling of `mutate`. Just like `mutate` it creates new columns. It however also removes all existing columns so that only the new columns remain.

####[task]
The time is currently encoded as decimal (e.g. `13.5` for 13:30). Create two columns `time_hours`, which contains the hour (13 in our example), and `time_minutes`, which contains the minutes, (30 in our example).

You can calculate `time_hours` as the floor of `time` (R function `floor`) and `time_minutes` as the remainder after integer division of 60 times `time` by 60 (R operator `%%`).
#####[answer]
We can create both columns in one call to `mutate`.
```{r}
bikes %>%
  mutate(time_hour=floor(time), time_minutes=(60*time)%%60)
```
The output does not show the new columns (as they would take the output of a single row to more than one line). We can show them all, for example, if we remove the station name.
```{r}
bikes %>%
  mutate(time_hour=floor(time), time_minutes=(60*time)%%60) %>%
  select(-name)
```
Alternatively, we can explicitly invoke the print method of the tibble and ask it to print everything.
```{r}
bikes %>%
  mutate(time_hour=floor(time), time_minutes=(60*time)%%60) %>%
  print(width=Inf)
```
#####[/answer]
####[/task]

### Sorting data sets using `arrange`
The function `arrange` can be used to sort a data set by one or more variables.
We can sort the data set `bikes` by the number of available bikes suing
```{r}
bikes %>%
  arrange(available_bikes)
```
You can use the function `desc` to sort in descending order
```{r}
bikes %>%
  arrange(desc(available_bikes))
```

####[task]
Identity the three bike stations that are furthest to the West (i.e. the ones with the smallest longitude `lng`).
#####[answer]
We first sort the stations by the longitude and the select to top three observations.
```{r}
stations %>%
  arrange(lng) %>%
  slice(1:3)
```

We could have also used the function `filter` and the ranking function `min_rank`:
```{r}
stations %>%
  filter(min_rank(lng)<=3)
```
`min_rank` returns the rank of the observation when considering the variable given as argument (there are many different ways of computing ranks, see `?min_rank` for details.)

However, the latter answer does not show the stations in increasing order of longitude. 
#####[/answer]
####[/task]

### Grouping data and calculating group-wise summary statistics: `group_by` and `summarise`

Suppose we want to identify the busiest stations in the system in the sense of having, on average, the most bikes taken out (and thus the highest number of available bike stands -- this is assuming JCDecaux replenish all bike stations in the same way, which is not quite what is happening in reality; there are better, but more complex, ways of defining "busy").

To calculate the average number of available bike stands per station we need to first group the data by bike station and then compute the average number of bike stands available
```{r}
bikes %>% group_by(name) %>%                             # Group by station name
  summarise(avg_stands=mean(available_bike_stands)) %>%  # Calculate averages
  arrange(desc(avg_stands))                              # Sort in descending order
```

####[task]
Can you think of another way of defining busy? Amend the commands accordingly.
#####[answer]
There are many possible alternatives. One would be to consider the standard deviation of the number of available bikes, i.e. we measure how much the number of available bikes fluctuates over time.
```{r}
bikes %>% group_by(name) %>%                   # Group by station name
  summarise(sd_bikes=sd(available_bikes)) %>%  # Calculate standard deviations
  arrange(desc(sd_bikes))                      # Sort in descending order
```
The answer obtained this way is rather different from what we have obtained before.
#####[/answer]
####[/task]

####[task]
Find the number of bike stations in each département.

You might find the function `n()` helpful, which returns the number of cases and is the `dplyr` equivalent of `COUNT(*)` in SQL (type `?n` to get help).

#####[answer]
We can use the following R code:
```{r}
stations %>% group_by(departement) %>%         # Group by department
  summarise(n_stations=n()) %>%                # Count cases
  arrange(desc(n_stations))                    # Sort in descending order
```
#####[/answer]
####[/task]

`group_by` can be also used to limit the scope of subsequent calls to other functions such as `filter`, `arrange` or `slice`. To make this more concrete, suppose we want to find for each time point the station which the most available bikes. We first have group the data by `time` and then find the station with the most available bikes.
```{r}
bikes %>%                                     
  group_by(time) %>%                           # Group by time
  arrange(desc(available_bikes)) %>%           # Sort by bikes within each group
  slice (1)                                    # Return only top one per group

```
Alternatively, we can use `filter` and `min_rank`:
```{r}
bikes %>%                                     
  group_by(time) %>%                           # Group by time
  filter(min_rank(desc(available_bikes))==1)   # Find largest in each group
```
You might have noticed that the answers differ a little. The reason for this are ties: for example, at 1.15pm the stations at Mussée d'Orsay, Mouffetard Epée de Bois and Sainte Placide Cherche-Midi all had 62 bikes available. The former commands extracts just one of them, whereas the bottom command extracts all three. 
(You would obtain the same results if you replaced `min_rank` by `row_number`, which breaks ties by using in doubt the order in the data set).

### Merging (joining) data sets using the `join`-type functions

Suppose we want to extract the data from `bikes` relating to bike stations in Hauts-de-Seine only. The table `bikes` does not however contain any information about the département in which the stations are located. We need to merge the information from the `stations` and `bikes`. This can be done using one of the `join` functions of `dplyr`. We will use `inner_join`, which only retains cases if there are corresponding entries in both data sets: this corresponds to the default behaviour of the R function `merge`.

The `join` functions will be default use the columns with common names across the two data sets ("natural join"). 

```{r}
bikes %>% inner_join(stations) %>%              # Merge data (using common variable: name)
  filter(departement=="Hauts-de-Seine")
```
We could have specified the column to used to join the data sets manually by adding the argument `by="name"` (or `by=c("name"="name")`, which allows using columns with different names in the two data set).


As a side note, in this example, we could have avoided joining the two tables. We could have first extracted the names of the stations in Hauts-de-Seine and then used those to subset the data from `bikes` (essentially the equivalent of a subquery in SQL):
```{r}
names92 <- stations %>% filter(departement=="Hauts-de-Seine") %>%
               select(name) 
bikes %>% filter(name %in% names92[[1]]) 
```
We had to use `names92[[1]]` to extract the entries of the tibble `names92` as a  character vector (we could have also used `unlist(names92)`).

You might notice a small difference in the results returned by the two approaches. The former retains the columns from `stations` which we have inserted, whereas the latter only contains the columns which `bikes` contained to start with.

####[task]
Merge the data sets `patients` and `weights` from the tasks from week 3. You can load the data sets using
```{r}
load(url("http://www.stats.gla.ac.uk/~levers/rp/patients_weights.RData"))
```
Use the merged data set to calculate the average weight of male and female patients.
#####[answer]
You can use the following R code:
```{r}
weights %>%                        
  inner_join(patients) %>%             # Merge with patients data (using common variable: PatientID)
  group_by(Gender) %>%                 # Group observations by gender
  summarise(AvgWeight=mean(Weight))    # Calculate group-wise means
```
#####[/answer]
####[/task]


### Translating dplyr statements into SQL commands

####[supplement]Translating dplyr statements into SQL commands

When working with large data sets stored in a relational database, it would be inefficient to transfer the data sets first into R and then manipulate them using `dplyr` in R. It will in almost all circumstances be faster to perform the data management in the database using SQL first and then importing the data into R. Also, R needs to store all data in memory, so combining large data sets might quickly exhaust R's memory.

However, you do not need to write the SQL statements yourself. The [dbplyr](https://cran.r-project.org/web/packages/dbplyr/) package automatically translates `dplyr` commands into SQL statements, so that you can still use `dplyr` commands in R as if the data was in R.

We will look at a small example using an in-memory SQLite database.
```{r}
library(dbplyr)                                  # Load required packages
library(DBI)
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(), ":memory:")  # Connect to temporary database
dbWriteTable(con, "stations", stations)          # Copy data to database
dbWriteTable(con, "bikes", bikes)                # (not needed in real world)

stations.db <- tbl(con, "stations")              # Define references to the tables
bikes.db <- tbl(con, "bikes")

query <- stations.db %>% filter(departement=="Seine-Saint-Denis" | departement=="Val-de-Marne")
                                                 # Translate dplyr instruction to query 

query %>% show_query()                           # Show the equivalent SQL statement

query %>% collect()                              # Run the query and show results

dbDisconnect(con)                                # Disconnect from the database
```

####[/supplement]


###[weblink, target="https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf"]Data Transformation Cheat Sheet
RStudio have put together a very handy and compact cheat sheet for dplyr. 
###[/weblink]



###[weblink, target="http://r4ds.had.co.nz/relational-data.html", icon="book"]Background reading: Chapter 13 of R for Data Science
Chapter 13 of *R for Data Science* gives a detailed overview of the functions in `dplyr`.
###[/weblink]

<!--[if PDF]>
\newpage
<![endif]-->
